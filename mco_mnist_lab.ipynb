{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mco-mnist-lab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SVY1pBg5ydH-"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mco-gh/DL-Workshop/blob/master/mco_mnist_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqLjB2cy5S7m"
      },
      "source": [
        "# Build a Digit Classification model on a Google TPU Using Keras and TensorFlow\n",
        "<table><tr><td><img valign=\"middle\" src=\"https://raw.githubusercontent.com/marcacohen/mnist-draw/master/mnist-draw.gif\" width=\"300\" alt=\"Keras+Tensorflow+Cloud TPU\"></td></tr></table>\n",
        "\n",
        "\n",
        "**This lab is derived from Martin Gorner's excellent, comprehensive, and highly recommended [Learn TensorFlow and deep learning, without a Ph.D.](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd) series.**\n",
        "\n",
        "This lab trains and evaluates a handwritten digit classification model using the MNIST dataset. It uses a Google Tensor Processing Unit (TPU) to speed up\n",
        "training and includes an interactive component that lets you test your model by drawing your own digits right inside this notebook.\n",
        "This notebook is provided for educational purposes only.\n",
        "\n",
        "Here's what we'll do in this lab:\n",
        "\n",
        "<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>&nbsp;&nbsp; Train on TPU</h3>\n",
        "\n",
        "Select a TPU backend (Runtime > Change runtime type)\n",
        "\n",
        "<h3><a href=\"https://www.tensorflow.org/js\"><img valign=\"middle\" src=\"data:image/png;base64,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\" width=\"50\"></a>&nbsp;&nbsp; Test our model interactively with TensorFlow.js</h3>\n",
        "\n",
        "Export our model for use in JavaScript and run an interactive web app to test the model interactively, with hand drawn digits.\n",
        "\n",
        "<h3><a href=\"https://cloud.google.com/ml-engine/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/mlengine-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Deploy to AI Platform</h3>\n",
        "At the bottom of this notebook you can deploy your trained model to AI Platform for a serverless, autoscaled, REST API experience. You will need a Google Cloud project and a GCS (Google Cloud Storage) bucket for this last part.\n",
        "\n",
        "TPUs are located in Google Cloud, for optimal performance, they read data directly from Google Cloud Storage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBd9QqHcYAS3"
      },
      "source": [
        "## Start with no accelerator\n",
        "\n",
        "In the Colab menu bar, select Runtime -> Change Runtime, set Runtime type to 'Python3', Hardware accelerator to 'None', and click SAVE.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/marcacohen/mnist-draw/master/img/cpu.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpiJj8ym0v0-"
      },
      "source": [
        "## Imports (*)\n",
        "These are Python modules we'll need throughout this lab, including TensorFlow, which is Google's open source framework for graph computation. The latter dependency is so critical to this lab that we also display the version of TensorFlow we're importing into this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoilhmYe1b5t"
      },
      "source": [
        "import os, re, time, json\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import IPython.display as display\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvo0t7XVIkWZ"
      },
      "source": [
        "## Parameters (*)\n",
        "\n",
        "These are global variables that allow to specify invariant constants that are useful throughout this lab. In particular, we'll specify things like the batch size and number of epochs (iterations through our training data), as well as URLs to our training and validation data. If you've never seen URLs of the form gs://, those are paths to objects in [Google Cloud Storage](http://cloud.google.com/storage)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCpkS9C_H7Tl"
      },
      "source": [
        "# The global batch size will be automatically sharded across all\n",
        "# replicas by the tf.data.Dataset API. A single TPU has 8 cores.\n",
        "# The best practice is to scale the batch size by the number of\n",
        "# replicas (cores). The learning rate should be increased as well.\n",
        "BATCH_SIZE = 64 # Gobal batch size.\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "training_images_file   = 'gs://mnist-public/train-images-idx3-ubyte'\n",
        "training_labels_file   = 'gs://mnist-public/train-labels-idx1-ubyte'\n",
        "validation_images_file = 'gs://mnist-public/t10k-images-idx3-ubyte'\n",
        "validation_labels_file = 'gs://mnist-public/t10k-labels-idx1-ubyte'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhwDVKf_OEpd"
      },
      "source": [
        "## Utility Functions (*)\n",
        "This section contains two collections of Python utility functions, which are required for proper execution but not critical for understanding the main ideas or the flow of this notebook. As such, both cells need to be executed but the contents are hidden. If you really want to understand every step along the way, feel free to unhide those cells and have a look at these utility functions. One of the nice things about working in Python is the code tends to be quite readable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV6i4Hbtf0hC",
        "cellView": "form"
      },
      "source": [
        "#@title Visualization Utilities [RUN ME]\n",
        "\"\"\"\n",
        "This cell contains helper functions used for visualization\n",
        "and downloads only. You can skip reading it. There is very\n",
        "little useful Keras/Tensorflow code here.\n",
        "\"\"\"\n",
        "\n",
        "# Matplotlib config\n",
        "plt.rc('image', cmap='gray_r')\n",
        "plt.rc('grid', linewidth=0)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
        "\n",
        "# pull a batch from the datasets. This code is not very nice, it gets much better in eager mode (TODO)\n",
        "def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n",
        "\n",
        "  # get one batch from each: 10000 validation digits, N training digits\n",
        "  batch_train_ds = training_dataset.apply(tf.data.experimental.unbatch()).batch(N)\n",
        "\n",
        "  # eager execution: loop through datasets normally\n",
        "  if tf.executing_eagerly():\n",
        "    for validation_digits, validation_labels in validation_dataset:\n",
        "      validation_digits = validation_digits.numpy()\n",
        "      validation_labels = validation_labels.numpy()\n",
        "      break\n",
        "    for training_digits, training_labels in batch_train_ds:\n",
        "      training_digits = training_digits.numpy()\n",
        "      training_labels = training_labels.numpy()\n",
        "      break\n",
        "\n",
        "  else:\n",
        "    v_images, v_labels = validation_dataset.make_one_shot_iterator().get_next()\n",
        "    t_images, t_labels = batch_train_ds.make_one_shot_iterator().get_next()\n",
        "    # Run once, get one batch. Session.run returns numpy results\n",
        "    with tf.Session() as ses:\n",
        "      (validation_digits, validation_labels,\n",
        "       training_digits, training_labels) = ses.run([v_images, v_labels, t_images, t_labels])\n",
        "\n",
        "  # these were one-hot encoded in the dataset\n",
        "  validation_labels = np.argmax(validation_labels, axis=1)\n",
        "  training_labels = np.argmax(training_labels, axis=1)\n",
        "\n",
        "  return (training_digits, training_labels,\n",
        "          validation_digits, validation_labels)\n",
        "\n",
        "# create digits from local fonts for testing\n",
        "def create_digits_from_local_fonts(n):\n",
        "  font_labels = []\n",
        "  img = PIL.Image.new('LA', (28*n, 28), color = (0,255)) # format 'LA': black in channel 0, alpha in channel 1\n",
        "  font1 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'DejaVuSansMono-Oblique.ttf'), 25)\n",
        "  font2 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'STIXGeneral.ttf'), 25)\n",
        "  d = PIL.ImageDraw.Draw(img)\n",
        "  for i in range(n):\n",
        "    font_labels.append(i%10)\n",
        "    d.text((7+i*28,0 if i<10 else -4), str(i%10), fill=(255,255), font=font1 if i<10 else font2)\n",
        "  font_digits = np.array(img.getdata(), np.float32)[:,0] / 255.0 # black in channel 0, alpha in channel 1 (discarded)\n",
        "  font_digits = np.reshape(np.stack(np.split(np.reshape(font_digits, [28, 28*n]), n, axis=1), axis=0), [n, 28*28])\n",
        "  return font_digits, font_labels\n",
        "\n",
        "# utility to display a row of digits with their predictions\n",
        "def display_digits(digits, predictions, labels, title, n):\n",
        "  plt.figure(figsize=(13,3))\n",
        "  digits = np.reshape(digits, [n, 28, 28])\n",
        "  digits = np.swapaxes(digits, 0, 1)\n",
        "  digits = np.reshape(digits, [28, 28*n])\n",
        "  plt.yticks([])\n",
        "  plt.xticks([28*x+14 for x in range(n)], predictions)\n",
        "  for i,t in enumerate(plt.gca().xaxis.get_ticklabels()):\n",
        "    if predictions[i] != labels[i]: t.set_color('red') # bad predictions in red\n",
        "  plt.imshow(digits)\n",
        "  plt.grid(None)\n",
        "  plt.title(title)\n",
        "\n",
        "# utility to display multiple rows of digits, sorted by unrecognized/recognized status\n",
        "def display_top_unrecognized(digits, predictions, labels, n, lines):\n",
        "  idx = np.argsort(predictions==labels) # sort order: unrecognized first\n",
        "  for i in range(lines):\n",
        "    display_digits(digits[idx][i*n:(i+1)*n], predictions[idx][i*n:(i+1)*n], labels[idx][i*n:(i+1)*n],\n",
        "                   \"{} sample validation digits out of {} with bad predictions in red and sorted first\".format(n*lines, len(digits)) if i==0 else \"\", n)\n",
        "\n",
        "def plot_learning_rate(lr_func, epochs):\n",
        "  xx = np.arange(epochs+1, dtype=np.float)\n",
        "  y = [lr_decay(x) for x in xx]\n",
        "  fig, ax = plt.subplots(figsize=(9, 6))\n",
        "  ax.set_xlabel('epochs')\n",
        "  ax.set_title('Learning rate\\ndecays from {:0.3g} to {:0.3g}'.format(y[0], y[-2]))\n",
        "  ax.minorticks_on()\n",
        "  ax.grid(True, which='major', axis='both', linestyle='-', linewidth=1)\n",
        "  ax.grid(True, which='minor', axis='both', linestyle=':', linewidth=0.5)\n",
        "  ax.step(xx,y, linewidth=3, where='post')\n",
        "  display.display(fig)\n",
        "\n",
        "class PlotTraining(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, steps_per_epoch, sample_rate=1, zoom=1):\n",
        "    self.sample_rate = sample_rate\n",
        "    self.step = 0\n",
        "    self.zoom = zoom\n",
        "    self.steps_per_epoch = steps_per_epoch\n",
        "\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.batch_history = {}\n",
        "    self.batch_step = []\n",
        "    self.epoch_history = {}\n",
        "    self.epoch_step = []\n",
        "    self.fig, self.axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "    plt.ioff()\n",
        "\n",
        "  def on_batch_end(self, batch, logs={}):\n",
        "    if (batch % self.sample_rate) == 0:\n",
        "      self.batch_step.append(self.step)\n",
        "      for k,v in logs.items():\n",
        "        # do not log \"batch\" and \"size\" metrics that do not change\n",
        "        # do not log training accuracy \"acc\"\n",
        "        if k=='batch' or k=='size':# or k=='acc':\n",
        "          continue\n",
        "        self.batch_history.setdefault(k, []).append(v)\n",
        "    self.step += 1\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    plt.close(self.fig)\n",
        "    self.axes[0].cla()\n",
        "    self.axes[1].cla()\n",
        "\n",
        "    self.axes[0].set_ylim(0, 1.2/self.zoom)\n",
        "    self.axes[1].set_ylim(1-1/self.zoom/2, 1+0.1/self.zoom/2)\n",
        "\n",
        "    self.epoch_step.append(self.step)\n",
        "    for k,v in logs.items():\n",
        "      # only log validation metrics\n",
        "      if not k.startswith('val_'):\n",
        "        continue\n",
        "      self.epoch_history.setdefault(k, []).append(v)\n",
        "\n",
        "  def on_train_end(self, logs={}):\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    for k,v in self.batch_history.items():\n",
        "      self.axes[0 if k.endswith('loss') else 1].plot(np.array(self.batch_step) / self.steps_per_epoch, v, label=k)\n",
        "\n",
        "    for k,v in self.epoch_history.items():\n",
        "      self.axes[0 if k.endswith('loss') else 1].plot(np.array(self.epoch_step) / self.steps_per_epoch, v, label=k, linewidth=3)\n",
        "\n",
        "    self.axes[0].legend()\n",
        "    self.axes[1].legend()\n",
        "    self.axes[0].set_xlabel('epochs')\n",
        "    self.axes[1].set_xlabel('epochs')\n",
        "    self.axes[0].minorticks_on()\n",
        "    self.axes[0].grid(True, which='major', axis='both', linestyle='-', linewidth=1)\n",
        "    self.axes[0].grid(True, which='minor', axis='both', linestyle=':', linewidth=0.5)\n",
        "    self.axes[1].minorticks_on()\n",
        "    self.axes[1].grid(True, which='major', axis='both', linestyle='-', linewidth=1)\n",
        "    self.axes[1].grid(True, which='minor', axis='both', linestyle=':', linewidth=0.5)\n",
        "    display.display(self.fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "OrmcMBApjSZN"
      },
      "source": [
        "#@title Data Processing Utilities [RUN ME]\n",
        "\"\"\"\n",
        "This cell contains helper functions used for data processing only. You can skip reading it. There is very\n",
        "little useful Keras/Tensorflow code here.\n",
        "\"\"\"\n",
        "\n",
        "def read_label(tf_bytestring):\n",
        "    label = tf.io.decode_raw(tf_bytestring, tf.uint8)\n",
        "    label = tf.reshape(label, [])\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return label\n",
        "\n",
        "def read_image(tf_bytestring):\n",
        "    image = tf.io.decode_raw(tf_bytestring, tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)/256.0\n",
        "    image = tf.reshape(image, [28*28])\n",
        "    return image\n",
        "\n",
        "def load_dataset(image_file, label_file):\n",
        "    imagedataset = tf.data.FixedLengthRecordDataset(image_file, 28*28, header_bytes=16)\n",
        "    imagedataset = imagedataset.map(read_image, num_parallel_calls=16)\n",
        "    labelsdataset = tf.data.FixedLengthRecordDataset(label_file, 1, header_bytes=8)\n",
        "    labelsdataset = labelsdataset.map(read_label, num_parallel_calls=16)\n",
        "    dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))\n",
        "    return dataset\n",
        "\n",
        "def get_training_dataset(image_file, label_file, batch_size):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache()  # this small dataset can be entirely cached in RAM\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True) # drop_remainder is important on TPU, batch size must be fixed\n",
        "    dataset = dataset.prefetch(-1)  # fetch next batches while training on the current one (-1: autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset(image_file, label_file):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache() # this small dataset can be entirely cached in RAM\n",
        "    dataset = dataset.batch(10000, drop_remainder=True) # 10000 items in eval dataset, all in one batch\n",
        "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA4fremPj3tU",
        "cellView": "form"
      },
      "source": [
        "#@title Training Utilities [RUN ME]\n",
        "\"\"\"\n",
        "This cell contains helper functions for compiling and training models.\n",
        "\"\"\"\n",
        "\n",
        "def set_strategy(accelerator):\n",
        "  strategy = None\n",
        "  if accelerator == 'tpu':\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu, steps_per_run=128) # Going back and forth between TPU and host is expensive. Better to run 128 batches on the TPU before reporting back.\n",
        "    print('TPU initialized: ', tpu.cluster_spec().as_dict()['worker'])\n",
        "  elif accelerator == 'gpu':\n",
        "    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    print('Running on single GPU ', gpus[0].name)\n",
        "  else:\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    print('Running on CPU')\n",
        "  print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "  batch_size = BATCH_SIZE*strategy.num_replicas_in_sync\n",
        "  LEARNING_RATE_EXP_DECAY = 0.6 if strategy.num_replicas_in_sync == 1 else 0.7\n",
        "  # Learning rate computed later as LEARNING_RATE * LEARNING_RATE_EXP_DECAY**epoch\n",
        "  # 0.7 decay instead of 0.6 means a slower decay, i.e. a faster learnign rate.\n",
        "  # set up learning rate decay\n",
        "  lr_decay = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: LEARNING_RATE * LEARNING_RATE_EXP_DECAY**epoch,\n",
        "    verbose=True)\n",
        "  training_dataset = get_training_dataset(training_images_file, training_labels_file, batch_size)\n",
        "  validation_dataset = get_validation_dataset(validation_images_file, validation_labels_file)\n",
        "  return (strategy, batch_size, lr_decay, training_dataset, validation_dataset)\n",
        "\n",
        "def compile(model):\n",
        "  model.compile(optimizer='adam', # learning rate will be set by LearningRateScheduler\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return\n",
        "\n",
        "def train(model, strategy, epochs=EPOCHS, batch_size=BATCH_SIZE):\n",
        "  steps_per_epoch = 60000 // batch_size  # 60,000 items in this dataset\n",
        "  print(\"steps_per_epoch=\", steps_per_epoch)\n",
        "\n",
        "  plot_training = PlotTraining(steps_per_epoch, sample_rate=1, zoom=1)\n",
        "  # Little wrinkle: in the present version of Tensorfow (1.14), switching a TPU\n",
        "  # between training and evaluation is slow (approx. 10 sec). For small models,\n",
        "  # it is recommeneded to run a single eval at the end.\n",
        "  history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch,\n",
        "                      epochs=EPOCHS, callbacks=[lr_decay, plot_training])\n",
        "\n",
        "  final_stats = model.evaluate(validation_dataset, steps=1)\n",
        "  print(\"Validation accuracy: \", final_stats[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fXo6GuvL3EB"
      },
      "source": [
        "## Let's have a look at the data\n",
        "\n",
        "Here we display 24 digits and their correponding labels, as a kind of quick sanity check of our training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ4tjPKvL2eh"
      },
      "source": [
        "(strategy, batch_size, lr_decay, training_dataset, validation_dataset) = set_strategy('cpu')\n",
        "N = 24\n",
        "(training_digits, training_labels,\n",
        " validation_digits, validation_labels) = dataset_to_numpy_util(training_dataset, validation_dataset, N)\n",
        "display_digits(training_digits, training_labels, training_labels, \"training digits and their labels\", N)\n",
        "display_digits(validation_digits[:N], validation_labels[:N], validation_labels[:N], \"validation digits and their labels\", N)\n",
        "font_digits, font_labels = create_digits_from_local_fonts(N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsvlAnHxl4UO"
      },
      "source": [
        "## First Try - A Naive Yet Functional Network\n",
        "\n",
        "In this first attempt at building a neural network to recognize handwritten digits, we're using about the simplest network imaginable. It's only two layers, one which has a node for every input pixel and then a dense layer (meaning fully connected to all the first layer nodes), which uses the softmax activation function to generate an output probility for each of ten given classes, representing the digits zero to nine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TXBlVVCl7-E"
      },
      "source": [
        "(strategy, batch_size, lr_decay, training_dataset, validation_dataset) = set_strategy('cpu')\n",
        "\n",
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.Input(shape=(28*28,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "  compile(model)\n",
        "\n",
        "model.summary()\n",
        "train(model, strategy)\n",
        "\n",
        "# recognize digits from local fonts\n",
        "probabilities = model.predict(font_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_digits(font_digits, predicted_labels, font_labels, \"predictions from local fonts (bad predictions in red)\", N)\n",
        "\n",
        "# recognize validation digits\n",
        "probabilities = model.predict(validation_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_top_unrecognized(validation_digits, predicted_labels, validation_labels, N, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIc0oqiD40HC"
      },
      "source": [
        "## A (much) better model: 3 convolutional layers, 2 dense layers (*)\n",
        "In this step we're fast forwarding to advance our model from a very simple naive approach to a much more sophisticated model, featuring five layers and including some advanced techniques, such as the rectfied linear unit activation function, Batch Normalization, and Dropout. Probably the most impactful advance here is the use the of convolution layers, which scan the input in a grid of related pixels, vs. treating each pixel in isolation. This improves the network's efficiency because it learns in a way that encompasses more context, just as our brains do when processing visual input.\n",
        "\n",
        "One thing to notice about specifying neural networks in Keras is the \"Lego-like\" way we can assemble relatively complex networks by snapping layers together in a sequential fashion.\n",
        "\n",
        "If you are not sure what cross-entropy, dropout, softmax or batch-normalization mean, head here for a crash-course: [Tensorflow and deep learning without a PhD](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd/#featured-code-sample)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC0kgPpz7Td2"
      },
      "source": [
        "def make_model():\n",
        " return tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1), name=\"image\"),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=12, kernel_size=3, padding='same', use_bias=False), # no bias necessary before batch norm\n",
        "    tf.keras.layers.BatchNormalization(scale=False, center=True), # no batch norm scaling necessary before \"relu\"\n",
        "    tf.keras.layers.Activation('relu'), # activation after batch norm\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=24, kernel_size=6, padding='same', use_bias=False, strides=2),\n",
        "    tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=6, padding='same', use_bias=False, strides=2),\n",
        "    tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(200, use_bias=False),\n",
        "    tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.Dropout(0.4), # Dropout on dense layer only\n",
        "\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDWtnyIMh0Xc"
      },
      "source": [
        "## Train and validate model on CPU\n",
        "So far we've only specified data structures defining out network but we haven't done anything with it yet! In essence, we've given Keras a blueprint for the network we want to build, train, and use to make predictions. In this step we compile the network, giving Keras three critical inputs:\n",
        "\n",
        "1. the optimizer, which dictates how Keras should find its way toward the best solution\n",
        "1. the loss function, which tells Keras how to assess the quality of our model's results at each iteration through the training data\n",
        "1 a set of metrics, not strictly required by Keras, but helpful for us to track how our model progresses toward its goal\n",
        "\n",
        "The call to model.summary() provides a terse textual representation of the model structure (we saw this output already with our naive model).\n",
        "\n",
        "Lastly, and perhaps most interestingly, the model.fit() method actually kicks of the training process. We pass that method everything Keras needs to train our model:  training data and labels,  validation data and labels, number of iterations (epochs), number of steps per epoch, and a list of callback functions, which Keras should invoke at the end of every epoch. The callback functions are used to update our learning rate and graph the training progress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-CQ7u4P7Fxp"
      },
      "source": [
        "(strategy, batch_size, lr_decay, training_dataset, validation_dataset) = set_strategy('cpu')\n",
        "\n",
        "with strategy.scope():\n",
        "  model = make_model()\n",
        "  compile(model)\n",
        "model.summary()\n",
        "train(model, strategy)\n",
        "\n",
        "# recognize digits from local fonts\n",
        "probabilities = model.predict(font_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_digits(font_digits, predicted_labels, font_labels, \"predictions from local fonts (bad predictions in red)\", N)\n",
        "\n",
        "# recognize validation digits\n",
        "probabilities = model.predict(validation_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_top_unrecognized(validation_digits, predicted_labels, validation_labels, N, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLpc2B-oUL_E"
      },
      "source": [
        "##STOP!!! THIS IS TAKING TOO LONG!!!\n",
        "Stop the cell above and let's retry training this model on a GPU..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWx4gnfLTtTq"
      },
      "source": [
        "## Train and validate the model on GPU\n",
        "\n",
        "In the Colab menu bar, select Runtime -> Change Runtime, set Runtime type to 'Python3', Hardware accelerator to 'GPU', and click SAVE.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/marcacohen/mnist-draw/master/img/gpu.png)\n",
        "\n",
        "**This action resets the runtime so you now need to rerun all the cells above marked with \"(*)\" before proceeding.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fio7ziuFS5ku"
      },
      "source": [
        "(strategy, batch_size, lr_decay, training_dataset, validation_dataset) = set_strategy('gpu')\n",
        "\n",
        "with strategy.scope():\n",
        "  model = make_model()\n",
        "  compile(model)\n",
        "model.summary()\n",
        "train(model, strategy, batch_size=batch_size)\n",
        "\n",
        "# recognize digits from local fonts\n",
        "probabilities = model.predict(font_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_digits(font_digits, predicted_labels, font_labels, \"predictions from local fonts (bad predictions in red)\", N)\n",
        "\n",
        "# recognize validation digits\n",
        "probabilities = model.predict(validation_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_top_unrecognized(validation_digits, predicted_labels, validation_labels, N, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuhDh8ao8VyB"
      },
      "source": [
        "## Train and validate the model on TPU\n",
        "Google provides special hardware called Tensor Processing Units, which are custom designed to perform the sort of tensor calculations that form the core of neural network training. As a result, using a TPU can vastly reduce your model's training time. Run this cell to restart training this model on a Google TPU and notice how much faster the process proceeds.\n",
        "\n",
        "The code in this cell is nearly identical to the previous cell, which tells you that you can include a TPU in your workflow with mimimal impact to your model training code.\n",
        "\n",
        "In the Colab menu bar, select Runtime -> Change Runtime, set Runtime type to 'Python3', Hardware accelerator to 'TPU', and click SAVE.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/marcacohen/mnist-draw/master/img/tpu.png)\n",
        "\n",
        "**This action resets the runtime so you now need to rerun all the cells above marked with \"(*)\" before proceeding.**\n",
        "\n",
        "Note that this is not the best  benchmark for TPUs (the TPU is probably at around 10% utilization when training this model) and it may not be much faster than using GPUs. But I'm using the MNIST model in this notebook because it's become a sort of \"Hello World\" example of Machine Learning in practice and it's helpful to use a simple model to show how easy it is to use TPUs in the Google Cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56y8UNFQIVwj"
      },
      "source": [
        "(strategy, batch_size, lr_decay, training_dataset, validation_dataset) = set_strategy('tpu')\n",
        "\n",
        "with strategy.scope():\n",
        "  model = make_model()\n",
        "  compile(model)\n",
        "model.summary()\n",
        "train(model, strategy, batch_size=batch_size)\n",
        "\n",
        "# recognize digits from local fonts\n",
        "probabilities = model.predict(font_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_digits(font_digits, predicted_labels, font_labels, \"predictions from local fonts (bad predictions in red)\", N)\n",
        "\n",
        "# recognize validation digits\n",
        "probabilities = model.predict(validation_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_top_unrecognized(validation_digits, predicted_labels, validation_labels, N, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_kBGkerzrss"
      },
      "source": [
        "## Save model and prep for use by TensorFlow.js\n",
        "We now want to run an interactive test where we draw digits right in this notebook and see how our model does in classifying them. For maximum responsiveness and low delay, we'll export our model so that it can be run in a browser using TensorFlow.js, and we'll also install a web server that provides the resources needed to provide this interactive drawing widget."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIBlNXQ6zxdp"
      },
      "source": [
        "model.save('mnist.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wCZtS8xWl1gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!grep batch_input_shape model/model.json"
      ],
      "metadata": {
        "id": "VfCdpT3Jq4da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbnw_xhNYLAP"
      },
      "source": [
        "%%shell\n",
        "pip install tensorflowjs\n",
        "rm -rf mnist-draw model\n",
        "tensorflowjs_converter --input_format keras mnist.h5 model/\n",
        "sed -i 's/input_shape/batch_input_shape/g' model/model.json\n",
        "git clone https://github.com/marcacohen/mnist-draw.git\n",
        "rm -rf mnist-draw/model\n",
        "mv model mnist-draw\n",
        "cd mnist-draw/\n",
        "\n",
        "pip install -q -r requirements.txt\n",
        "cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68y1DPKNXgRM"
      },
      "source": [
        "## Run Some Interactive Tests\n",
        "Run this cell to launch the interactive digit drawing canvas, which will enable you to draw digits with your mouse and classify them using the model you built in this notebook. See how well your model performs. Can you find any weaknesses?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46hTdUjAYHVg"
      },
      "source": [
        "import http.server\n",
        "import socketserver\n",
        "import portpicker\n",
        "import threading\n",
        "import os\n",
        "from google.colab import output\n",
        "from IPython.display import Javascript\n",
        "\n",
        "started = threading.Event()\n",
        "port = portpicker.pick_unused_port()\n",
        "\n",
        "# Start a background thread serving up the files.\n",
        "def server_entry():\n",
        "  os.chdir('/content/mnist-draw')\n",
        "  with socketserver.TCPServer((\"\", port), http.server.SimpleHTTPRequestHandler) as httpd:\n",
        "    started.set()\n",
        "    httpd.serve_forever()\n",
        "\n",
        "thread = threading.Thread(target=server_entry)\n",
        "thread.start()\n",
        "started.wait();\n",
        "\n",
        "# Tell the JS side the port #\n",
        "output.eval_js(f\"window.mnistPort = {port}\")\n",
        "\n",
        "Javascript('''\n",
        "  (async () => {\n",
        "    if (!google.colab.kernel.accessAllowed) {\n",
        "        // User needs to execute the notebook.\n",
        "        return;\n",
        "    }\n",
        "    const url = await google.colab.kernel.proxyPort(window.mnistPort);\n",
        "    const iframe = document.createElement('iframe');\n",
        "    iframe.src = url;\n",
        "    iframe.height = '500px';\n",
        "    iframe.width = '100%';\n",
        "    iframe.style.border = '0';\n",
        "    document.body.appendChild(iframe);\n",
        "  })()\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tzVi39ShrEL"
      },
      "source": [
        "## Deploy the trained model to AI Platform\n",
        "\n",
        "In this section we will push your trained model to production on AI Platform for a serverless, autoscaled, REST API experience.\n",
        "\n",
        "You will need a GCS bucket and a GCP project for this.\n",
        "Models deployed on ML Engine autoscale to zero if not used. There will be no ML Engine charges after you are done testing.\n",
        "Google Cloud Storage incurs charges. Empty the bucket after deployment if you want to avoid these. Once the model is deployed, the bucket is not useful anymore."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzd6Qi464PsA"
      },
      "source": [
        "### Authentication for TPU Access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "MPx0nvyUnvgT"
      },
      "source": [
        "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n",
        "if IS_COLAB_BACKEND:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user() # Authenticates the backend and also the TPU using your credentials so that they can access your private GCS buckets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y3ztMY_toCP"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5tI9exutpfV"
      },
      "source": [
        "PROJECT = \"mco-keras\" #@param {type:\"string\"}\n",
        "BUCKET = \"gs://mco-keras\"  #@param {type:\"string\", default:\"jddj\"}\n",
        "NEW_MODEL = True #@param {type:\"boolean\"}\n",
        "MODEL_NAME = \"mnist\" #@param {type:\"string\"}\n",
        "MODEL_VERSION = \"v1\" #@param {type:\"string\"}\n",
        "\n",
        "assert PROJECT, 'For this part, you need a GCP project. Head to http://console.cloud.google.com/ and create one.'\n",
        "assert re.search(r'gs://.+', BUCKET), 'For this part, you need a GCS bucket. Head to http://console.cloud.google.com/storage and create one.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxQTtjmdIbmN"
      },
      "source": [
        "### Export the model for serving from AI Platform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOgh7Kb7SzzG"
      },
      "source": [
        "# Wrap the model so that we can add a serving function\n",
        "class ExportModel(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__(self)\n",
        "    self.model = model\n",
        "\n",
        "  # The serving function performig data pre- and post-processing.\n",
        "  # Pre-processing:  images are received in uint8 format converted\n",
        "  #                  to float32 before being sent to through the model.\n",
        "  # Post-processing: the Keras model outputs digit probabilities. We want\n",
        "  #                  the detected digits. An additional tf.argmax is needed.\n",
        "  # @tf.function turns the code in this function into a Tensorflow graph that\n",
        "  # can be exported. This way, the model itself, as well as its pre- and post-\n",
        "  # processing steps are exported in the SavedModel and deployed in a single step.\n",
        "  @tf.function(input_signature=[tf.TensorSpec([None, 28*28], dtype=tf.uint8)])\n",
        "  def my_serve(self, images):\n",
        "    images = tf.cast(images, tf.float32)/255   # pre-processing\n",
        "    probabilities = self.model(images)          # prediction from model\n",
        "    classes = tf.argmax(probabilities, axis=-1) # post-processing\n",
        "    return {'digits': classes}\n",
        "\n",
        "# Must copy the model from TPU to CPU to be able to compose them.\n",
        "restored_model = make_model()\n",
        "restored_model.set_weights(model.get_weights()) # this copies the weights from TPU, does nothing on GPU\n",
        "\n",
        "# create the ExportModel and export it to the Tensorflow standard SavedModel format\n",
        "serving_model = ExportModel(restored_model)\n",
        "export_path = os.path.join(BUCKET, 'keras_export', str(time.time()))\n",
        "tf.keras.backend.set_learning_phase(0) # inference only\n",
        "tf.saved_model.save(serving_model, export_path, signatures={'serving_default': serving_model.my_serve})\n",
        "\n",
        "print(\"Model exported to: \", export_path)\n",
        "\n",
        "# Note: in Tensorflow 2.0, it will also be possible to\n",
        "# export to the SavedModel format using model.save():\n",
        "# serving_model.save(export_path, save_format='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm7cpCRQC8-w"
      },
      "source": [
        "# saved_model_cli: a useful tool for troubleshooting SavedModels (the tool is part of the Tensorflow installation)\n",
        "!saved_model_cli show --dir {export_path}\n",
        "!saved_model_cli show --dir {export_path} --tag_set serve\n",
        "!saved_model_cli show --dir {export_path} --tag_set serve --signature_def serving_default\n",
        "# A note on naming:\n",
        "# The \"serve\" tag set (i.e. serving functionality) is the only one exported by tf.saved_model.save\n",
        "# All the other names are defined by the user in the fllowing lines of code:\n",
        "#      def myserve(self, images):\n",
        "#                        ******\n",
        "#        return {'digits': classes}\n",
        "#                 ******\n",
        "#      tf.saved_model.save(..., signatures={'serving_default': serving_model.myserve})\n",
        "#                                            ***************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy3T3zk0u2J0"
      },
      "source": [
        "### Deploy the model\n",
        "This uses the command-line interface. You can do the same thing through the AI Platform UI at https://console.cloud.google.com/mlengine/models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGv3ITiGLPL3"
      },
      "source": [
        "# Create the model\n",
        "if NEW_MODEL:\n",
        "  !gcloud ai-platform models create {MODEL_NAME} --project={PROJECT} --regions=us-central1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3QtUowtOAL-"
      },
      "source": [
        "# Create a version of this model (you can add --async at the end of the line to make this call non blocking)\n",
        "# Additional config flags are available: https://cloud.google.com/ml-engine/reference/rest/v1/projects.models.versions\n",
        "# You can also deploy a model that is stored locally by providing a --staging-bucket=... parameter\n",
        "!echo \"Deployment takes a couple of minutes. You can watch your deployment here: https://console.cloud.google.com/mlengine/models/{MODEL_NAME}\"\n",
        "!gcloud ai-platform versions create {MODEL_VERSION} --model={MODEL_NAME} --origin={export_path} --project={PROJECT} --runtime-version=1.14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE-k1Zn6kU2Z"
      },
      "source": [
        "### Test the deployed model\n",
        "Your model is now available as a REST API. Let us try to call it. The cells below use the \"gcloud ml-engine\"\n",
        "command line tool but any tool that can send a JSON payload to a REST endpoint will work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZCt0Ke2QDer"
      },
      "source": [
        "# prepare digits to send to online prediction endpoint\n",
        "digits_float32 = np.concatenate((font_digits, validation_digits[:100-N])) # pixel values in [0.0, 1.0] float range\n",
        "digits_uint8 = np.round(digits_float32*255).astype(np.uint8) # pixel values in [0, 255] int range\n",
        "labels = np.concatenate((font_labels, validation_labels[:100-N]))\n",
        "with open(\"digits.json\", \"w\") as f:\n",
        "  for digit in digits_uint8:\n",
        "    # the format for AI Platform online predictions is: one JSON object per line\n",
        "    data = json.dumps({\"images\": digit.tolist()})  # \"images\" because that was the name you gave this parametr in the serving funtion my_serve\n",
        "    f.write(data+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek344oDJugRe"
      },
      "source": [
        "# Request online predictions from deployed model (REST API) using the \"gcloud ml-engine\" command line.\n",
        "predictions = !gcloud ai-platform predict --model={MODEL_NAME} --json-instances digits.json --project={PROJECT} --version {MODEL_VERSION}\n",
        "print(predictions)\n",
        "\n",
        "predictions = np.stack([json.loads(p) for p in predictions[1:]]) # first elemet is the name of the output layer: drop it, parse the rest\n",
        "display_top_unrecognized(digits_float32, predictions, labels, N, 100//N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVY1pBg5ydH-"
      },
      "source": [
        "## License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "author: Martin Gorner<br>\n",
        "twitter: @martin_gorner<br>\n",
        "Revised by: Marc Cohen (added text annotations, CPU vs. GPU vs. TPU training, interactive JS widget)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Copyright 2019 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose\n"
      ]
    }
  ]
}